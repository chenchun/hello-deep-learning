import torch
from eplb_dispatch import dispatch_tokens_to_phy_id, dispatch_tokens_to_phy_id_2
import torch.utils.benchmark as benchmark

# @torch.compile(dynamic=True)
def torch_dispatch_tokens_to_phy_id_raw(
        topk_weights: torch.Tensor,
        topk_ids: torch.Tensor,
        expert_count: torch.Tensor,
        log2phy: torch.Tensor,
) -> torch.tensor:
    expert_counts = expert_count[topk_ids]
    selected_experts = torch.remainder((topk_weights * 10000).int(),
                                        expert_counts)
    # [num_tokens, topk, max_num_redundant_expert]
    topk_phy_ids = log2phy[topk_ids]
    # convert from [num_tokens, topk(0-x)] to [num_tokens, topk(phy_id)]
    topk_phy_ids = topk_phy_ids.gather(
        2, selected_experts.unsqueeze(-1).to(dtype=torch.int64)).squeeze(-1).type(topk_ids.dtype)
    return topk_phy_ids

torch_dispatch_tokens_to_phy_id = torch.compile(torch_dispatch_tokens_to_phy_id_raw)

tokens=50000

log2phy = torch.tensor(
    [[ 47,  -1,  -1],
         [252,  -1,  -1],
         [184,  -1,  -1],
         [137,  69, 103],
         [139,  -1,  -1],
         [ 84,  -1,  -1],
         [  5,  -1,  -1],
         [244,  -1,  -1],
         [116,  -1,  -1],
         [ 40,  -1,  -1],
         [ 35,  -1,  -1],
         [141,  -1,  -1],
         [  9,  -1,  -1],
         [ 15,  -1,  -1],
         [251,  -1,  -1],
         [  3,   4,  -1],
         [242,  -1,  -1],
         [ 71,  -1,  -1],
         [136, 102,  -1],
         [ 38, 140,  -1],
         [ 51,  -1,  -1],
         [ 91,  -1,  -1],
         [121,  -1,  -1],
         [208,  -1,  -1],
         [ 17,  -1,  -1],
         [154,  -1,  -1],
         [115,  -1,  -1],
         [ 14,  -1,  -1],
         [216,  -1,  -1],
         [263,  -1,  -1],
         [178,  -1,  -1],
         [211,  -1,  -1],
         [217,  -1,  -1],
         [194,  -1,  -1],
         [ 55,  -1,  -1],
         [ 53,  -1,  -1],
         [107,  -1,  -1],
         [173,  -1,  -1],
         [152,  -1,  -1],
         [ 92,  -1,  -1],
         [254,  -1,  -1],
         [ 75,  -1,  -1],
         [  0,  34,  -1],
         [172,  36, 240],
         [106,  -1,  -1],
         [219,  -1,  -1],
         [109,  -1,  -1],
         [250,  -1,  -1],
         [212,  -1,  -1],
         [ 43,  -1,  -1],
         [229,  -1,  -1],
         [142,  -1,  -1],
         [151,  -1,  -1],
         [ 49,  -1,  -1],
         [108,  -1,  -1],
         [243,  -1,  -1],
         [213,  -1,  -1],
         [124,  -1,  -1],
         [111,  -1,  -1],
         [222,  -1,  -1],
         [ 54,  -1,  -1],
         [209,  -1,  -1],
         [174,  -1,  -1],
         [ 41,  -1,  -1],
         [ 73,  -1,  -1],
         [ 25,  -1,  -1],
         [ 72,  -1,  -1],
         [  7,  -1,  -1],
         [ 80,  -1,  -1],
         [ 74,  -1,  -1],
         [120,  -1,  -1],
         [ 57,  -1,  -1],
         [179,  -1,  -1],
         [165,  -1,  -1],
         [ 68,  -1,  -1],
         [176,  -1,  -1],
         [ 59,  -1,  -1],
         [191,  -1,  -1],
         [155,  -1,  -1],
         [239, 238,  -1],
         [245,  -1,  -1],
         [206, 104, 138],
         [147,  -1,  -1],
         [210,  -1,  -1],
         [ 78,  -1,  -1],
         [ 63,  -1,  -1],
         [260,  -1,  -1],
         [110,  -1,  -1],
         [ 21,  -1,  -1],
         [ 93,  -1,  -1],
         [ 11,  -1,  -1],
         [ 23,  -1,  -1],
         [ 45,  -1,  -1],
         [130,  -1,  -1],
         [161,  -1,  -1],
         [193,  -1,  -1],
         [ 39,  -1,  -1],
         [189,  -1,  -1],
         [ 20,  -1,  -1],
         [261,  -1,  -1],
         [ 46,  -1,  -1],
         [177,  -1,  -1],
         [249,  -1,  -1],
         [ 52,  -1,  -1],
         [113,  -1,  -1],
         [247,  -1,  -1],
         [258,  -1,  -1],
         [256,  -1,  -1],
         [207,  37, 241],
         [ 81,  -1,  -1],
         [ 79,  -1,  -1],
         [187,  -1,  -1],
         [112,  -1,  -1],
         [253,  -1,  -1],
         [ 42,  -1,  -1],
         [ 22,  -1,  -1],
         [ 18,  -1,  -1],
         [156,  -1,  -1],
         [ 56,  -1,  -1],
         [ 44,  -1,  -1],
         [171, 205,  -1],
         [148,  -1,  -1],
         [131,  -1,  -1],
         [146,  -1,  -1],
         [ 62,  -1,  -1],
         [180,  -1,  -1],
         [175,  -1,  -1],
         [246,  -1,  -1],
         [186,  -1,  -1],
         [ 94,  -1,  -1],
         [231,  -1,  -1],
         [ 50,  -1,  -1],
         [ 27,  -1,  -1],
         [ 48,  -1,  -1],
         [128,  -1,  -1],
         [135,  -1,  -1],
         [  8,  -1,  -1],
         [ 89,  -1,  -1],
         [192,  -1,  -1],
         [ 98,  -1,  -1],
         [ 85,  -1,  -1],
         [ 24,  -1,  -1],
         [268,  -1,  -1],
         [158,  -1,  -1],
         [132,  -1,  -1],
         [169,  -1,  -1],
         [266,  -1,  -1],
         [144,  -1,  -1],
         [163,  -1,  -1],
         [181,  -1,  -1],
         [ 90,  -1,  -1],
         [  6,  -1,  -1],
         [ 77,  -1,  -1],
         [215,  -1,  -1],
         [183,  -1,  -1],
         [227,  -1,  -1],
         [236,  -1,  -1],
         [ 82,  -1,  -1],
         [129,  -1,  -1],
         [150,  -1,  -1],
         [262,  -1,  -1],
         [170, 204,  -1],
         [ 95,  -1,  -1],
         [182,  -1,  -1],
         [126,  -1,  -1],
         [267,  -1,  -1],
         [235,  -1,  -1],
         [149,  -1,  -1],
         [270,  -1,  -1],
         [160,  -1,  -1],
         [185,  -1,  -1],
         [ 10,  -1,  -1],
         [ 31,  -1,  -1],
         [ 65,  -1,  -1],
         [221,  -1,  -1],
         [119,  -1,  -1],
         [127,  -1,  -1],
         [196,  -1,  -1],
         [ 60,  -1,  -1],
         [  2,  70,  -1],
         [ 67,  -1,  -1],
         [230,  -1,  -1],
         [199,  -1,  -1],
         [257,  -1,  -1],
         [ 66,  -1,  -1],
         [ 13,  -1,  -1],
         [ 26,  -1,  -1],
         [271,  -1,  -1],
         [ 64,  -1,  -1],
         [195,  -1,  -1],
         [234,  -1,  -1],
         [ 61,  -1,  -1],
         [ 83,  -1,  -1],
         [162,  -1,  -1],
         [200,  -1,  -1],
         [ 16,  -1,  -1],
         [188,  -1,  -1],
         [143,  -1,  -1],
         [  1,  -1,  -1],
         [ 96,  -1,  -1],
         [ 76,  -1,  -1],
         [125,  -1,  -1],
         [100,  -1,  -1],
         [218,  -1,  -1],
         [118,  -1,  -1],
         [237,  -1,  -1],
         [ 29,  -1,  -1],
         [265,  -1,  -1],
         [159,  -1,  -1],
         [122,  -1,  -1],
         [233,  -1,  -1],
         [ 99,  -1,  -1],
         [202,  -1,  -1],
         [203,  -1,  -1],
         [105,  -1,  -1],
         [228,  -1,  -1],
         [153,  -1,  -1],
         [220,  -1,  -1],
         [225,  -1,  -1],
         [114,  -1,  -1],
         [259,  -1,  -1],
         [197,  -1,  -1],
         [224,  -1,  -1],
         [ 87,  -1,  -1],
         [166,  -1,  -1],
         [168,  -1,  -1],
         [ 12,  -1,  -1],
         [ 28,  -1,  -1],
         [101,  -1,  -1],
         [ 32,  -1,  -1],
         [145,  -1,  -1],
         [ 19,  -1,  -1],
         [134,  -1,  -1],
         [ 58,  -1,  -1],
         [190,  -1,  -1],
         [214,  -1,  -1],
         [255,  -1,  -1],
         [223,  -1,  -1],
         [ 88,  -1,  -1],
         [ 33,  -1,  -1],
         [ 86,  -1,  -1],
         [226,  -1,  -1],
         [117,  -1,  -1],
         [248,  -1,  -1],
         [269,  -1,  -1],
         [264,  -1,  -1],
         [133,  -1,  -1],
         [198,  -1,  -1],
         [201,  -1,  -1],
         [157,  -1,  -1],
         [164,  -1,  -1],
         [167,  -1,  -1],
         [ 97,  -1,  -1],
         [123,  -1,  -1],
         [232,  -1,  -1],
         [ 30,  -1,  -1]], device='cuda', dtype=torch.int32)
expert_count = torch.tensor([1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda', dtype=torch.int32)
topk_weights = torch.rand(tokens, 8, device='cuda')
topk_ids = torch.rand(tokens, 8, device='cuda')*expert_count.shape[-1]
topk_ids = topk_ids.to(dtype=torch.int32)
assert dispatch_tokens_to_phy_id(topk_weights, topk_ids, expert_count, log2phy).allclose(
    torch_dispatch_tokens_to_phy_id(topk_weights, topk_ids, expert_count, log2phy))
assert torch_dispatch_tokens_to_phy_id(topk_weights, topk_ids, expert_count, log2phy).allclose(
    dispatch_tokens_to_phy_id_2(topk_weights, topk_ids, expert_count, log2phy))

t0 = benchmark.Timer(
    stmt='dispatch_tokens_to_phy_id(topk_weights, topk_ids, expert_count, log2phy)',
    setup='from eplb_dispatch import dispatch_tokens_to_phy_id',
    globals={
        'topk_weights': topk_weights,
        'topk_ids': topk_ids,
        'expert_count': expert_count,
        'log2phy': log2phy,
    })

t1 = benchmark.Timer(
    stmt='dispatch_tokens_to_phy_id_2(topk_weights, topk_ids, expert_count, log2phy)',
    setup='from eplb_dispatch import dispatch_tokens_to_phy_id_2',
    globals={
        'topk_weights': topk_weights,
        'topk_ids': topk_ids,
        'expert_count': expert_count,
        'log2phy': log2phy,
    })

t2 = benchmark.Timer(
    stmt='torch_dispatch_tokens_to_phy_id(topk_weights, topk_ids, expert_count, log2phy)',
    setup='from __main__ import torch_dispatch_tokens_to_phy_id',
    globals={
        'topk_weights': topk_weights,
        'topk_ids': topk_ids,
        'expert_count': expert_count,
        'log2phy': log2phy,
    })

print(t0.timeit(100))
print(t1.timeit(100))
print(t2.timeit(100))


results = []

for tokens in (1, 4, 10, 20, 40, 80, 160, 320, 640, 1280, 2560, 5120, 10240, 20480, 40960, 81920, 163840, 327680, 655360):
    # label and sub_label are the rows
    # description is the column
    label = 'Batched dot'
    sub_label = f'tokens={tokens}'
    topk_weights = torch.rand(tokens, 8, device='cuda')
    topk_ids = torch.rand(tokens, 8, device='cuda')*expert_count.shape[-1]
    topk_ids = topk_ids.to(dtype=torch.int32)
    for num_threads in [1, 4]:
        results.append(benchmark.Timer(
            stmt='torch_dispatch_tokens_to_phy_id(topk_weights, topk_ids, expert_count, log2phy)',
            setup='from __main__ import torch_dispatch_tokens_to_phy_id',
            globals={
                'topk_weights': topk_weights,
                'topk_ids': topk_ids,
                'expert_count': expert_count,
                'log2phy': log2phy,
            },
            num_threads=num_threads,
            label=label,
            sub_label=sub_label,
            description='torch_dispatch_tokens_to_phy_id',
        ).blocked_autorange(min_run_time=0.5))
        results.append(benchmark.Timer(
            stmt='dispatch_tokens_to_phy_id(topk_weights, topk_ids, expert_count, log2phy)',
            setup='from eplb_dispatch import dispatch_tokens_to_phy_id',
            globals={
                'topk_weights': topk_weights,
                'topk_ids': topk_ids,
                'expert_count': expert_count,
                'log2phy': log2phy,
            },
            num_threads=num_threads,
            label=label,
            sub_label=sub_label,
            description='dispatch_tokens_to_phy_id',
        ).blocked_autorange(min_run_time=0.5))
        results.append(benchmark.Timer(
            stmt='dispatch_tokens_to_phy_id_2(topk_weights, topk_ids, expert_count, log2phy)',
            setup='from eplb_dispatch import dispatch_tokens_to_phy_id_2',
            globals={
                'topk_weights': topk_weights,
                'topk_ids': topk_ids,
                'expert_count': expert_count,
                'log2phy': log2phy,
            },
            num_threads=num_threads,
            label=label,
            sub_label=sub_label,
            description='dispatch_tokens_to_phy_id_2',
        ).blocked_autorange(min_run_time=0.5))

compare = benchmark.Compare(results)
compare.colorize()
compare.print()